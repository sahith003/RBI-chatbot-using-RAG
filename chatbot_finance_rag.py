# -*- coding: utf-8 -*-
"""chatbot_finance_RaG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XCnj57p7Qrv1kV9q0C6bIOZa3W9gRF_q
"""

!pip install flask flask-ngrok langchain langchain-openai langchain-community faiss-cpu tiktoken PyPDF2

!pip install unstructured[pdf]

!pip install pyngrok



from flask import Flask, request, jsonify, render_template
from pyngrok import ngrok, conf
from langchain_openai import OpenAIEmbeddings, OpenAI
from langchain.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders import DirectoryLoader
import os

# === CONFIGURATION ===

# Read OpenAI API key from file
with open("/content/drive/MyDrive/keys/key_1.txt", "r") as f:
    openai_api = f.read().strip()

TEMPLATE_DIR = "/content/drive/MyDrive/gen_ai_chatbot_new/templates"
PDF_DIR = "/content/drive/MyDrive/gen_ai_chatbot_new/data"
os.makedirs(PDF_DIR, exist_ok=True)

# Ngrok auth token â€” replace with your actual token
NGROK_AUTH_TOKEN = "2xoRPCX2jEsOKNzkEQ2Ushh3ey3_347zL1by8KnVM5DzehZzS"
conf.get_default().auth_token = NGROK_AUTH_TOKEN


# === LangChain Chatbot Setup ===
def get_llm(path, api_key):
    loader = DirectoryLoader(path)
    documents = loader.load()

    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(documents)

    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vector_db = FAISS.from_documents(texts, embeddings)
    llm = OpenAI(openai_api_key=api_key)

    qa = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_db.as_retriever(),
        chain_type="stuff"
    )
    return qa

# Initialize chatbot
chatbot = get_llm(PDF_DIR, openai_api)

# === Flask Setup ===
app = Flask(__name__,template_folder=TEMPLATE_DIR)

@app.route("/")
def home():
    return render_template("index.html")  # Your HTML template

@app.route('/get_answer', methods=["POST"])
def get_answer():
    question = request.form['question']
    response = chatbot.invoke({'question': question, 'chat_history': []})
    return jsonify(response)

# Open a public tunnel on port 5000
public_url = ngrok.connect(5000)
print(f" * ngrok tunnel running at: {public_url}")

# Run Flask app
app.run(port=5000)